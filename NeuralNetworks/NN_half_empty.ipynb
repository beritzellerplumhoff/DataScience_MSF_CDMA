{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389557e3",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "\n",
    "Copyright (C) 2023-2024, B. Zeller-Plumhoff\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the [GNU General Public License](https://www.gnu.org/licenses/gpl-3.0.html) for more details.\n",
    "\n",
    "This Jupyter Notebook was created by Berit Zeller-Plumhoff. \n",
    "\n",
    "Within the notebook, you will perform a classification of metallicity using logistic regression, $k$-nearest neighbours and decision trees. Varying the $k$ and depth of the tree, you will assess how these influence your results and compare the performance of the different classifiers using ROC metrics and curves.\n",
    "\n",
    "<span style='color:red'> You will also include random forests classifiers in this notebook this week. </span>\n",
    "\n",
    "<span style='color:red'> You will also include support vector machine classifiers in this notebook this week. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550ddff",
   "metadata": {},
   "source": [
    "We begin by loading the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a437697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # library for organizing data\n",
    "import numpy as np # library for numerial computations\n",
    "from sklearn import linear_model # the linear_model library establishes a straightforward implementation of a linear regression model\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score # this library enables the splitting of a data set into training and test data\n",
    "from sklearn.inspection import DecisionBoundaryDisplay # library to display decision boundaries of classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, RocCurveDisplay, roc_curve, roc_auc_score, log_loss, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt # library for plotting (not interactive)\n",
    "import matminer.datasets as mm # library for data mining materials properties, accesses published datasets\n",
    "from matminer.featurizers.conversions import StrToComposition # converts a string denoting a material composition into the composition\n",
    "from matminer.featurizers.composition.element import ElementFraction # determines the element fraction for a given composition\n",
    "from pymatgen.core import Composition # materials analysis library, module used to analyse the chemical composition of a compound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc820e82",
   "metadata": {},
   "source": [
    "### Predicting metallicity\n",
    "\n",
    "For classification of metallicit based on the material compositon, we will use the dataset based on the publication from [Zhuo et al., 2018](https://pubs.acs.org/doi/pdf/10.1021/acs.jpclett.8b00124)<a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1) that can be accessed through __matminer__. Have a look at last week's notebook to learn more about the dataset and __matminer__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a368751b",
   "metadata": {},
   "source": [
    "In this case, we will start by loading the pickle file which we prepared previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1efda0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_pickle('../data/ismetal_df.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a1eb46",
   "metadata": {},
   "source": [
    "Assign the dataframe __without__ columns \"formula\" \"is_metal\" and \"composition\" to your feature variable X and the \"is_metal\" column to the observation y. Then split this data into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db1592db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the variables\n",
    "X=df.drop([\"formula\",\"is_metal\",\"composition\"],axis=1)\n",
    "y=df[\"is_metal\"]\n",
    "\n",
    "# split your data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f068d",
   "metadata": {},
   "source": [
    "Now we will sort the data we created above using different algorithms. To do so, use the train data to fit and the test data to predict the classifiers. Do this by employing the [__logistic regression__](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression), the [__k-nearest neighbors__](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), and the [__decision tree__](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) classification methods. In the case of classification using __k-nearest neighbors__, we will make predictions considering different numbers of nearest neighbors. The same will be done for the __decision tree__ and the maximum depth of the tree. This can be performed within a loop, where you will __append__ the current model and predictions to a list thereof, which will initially be empty. For the loop, consider the range from $\\left[1, 20\\right]$. Read the documentation for these methods if necessary. \n",
    "\n",
    "<span style='color:red'> Add the [__random forest__](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#) classifier, looping over the number of estimators to include in the ensemble from $\\left[1, 100\\right]$ in steps of 10. </span>\n",
    "\n",
    "<span style='color:red'> Add the [__support vector machine__](https://scikit-learn.org/stable/modules/svm.html#classification) classifier(s) according to the specification developed in the original paper (try setting the parameters as given in the paper or not). </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca2a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "model_log_reg = linear_model.LogisticRegression()\n",
    "model_log_reg=model_log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = model_log_reg.predict(X_test)\n",
    "\n",
    "# k-nearest neighbors (loop over k)\n",
    "model_knn=[]\n",
    "y_pred_knn=[]\n",
    "for k in range(1,21):\n",
    "    model_knn_tmp = KNeighborsClassifier(n_neighbors=k)\n",
    "    model_knn.append(model_knn_tmp.fit(X_train, y_train))\n",
    "    y_pred_knn.append(model_knn_tmp.predict(X_test))\n",
    "\n",
    "# decision tree (loop over max_depth)\n",
    "model_tree=[]\n",
    "y_pred_tree=[]\n",
    "for i in range(1,21):\n",
    "    model_tree_tmp = DecisionTreeClassifier(max_depth=i)\n",
    "    model_tree.append(model_tree_tmp.fit(X_train, y_train))\n",
    "    y_pred_tree.append(model_tree_tmp.predict(X_test))\n",
    "    \n",
    "# random forests (loop over n_estimators in steps of 50, i.e. 1, 50, 100, 150...)\n",
    "model_rf=[]\n",
    "y_pred_rf=[]\n",
    "model_rf_tmp = RandomForestClassifier(n_estimators=1) \n",
    "model_rf.append(model_rf_tmp.fit(X_train, y_train))\n",
    "y_pred_rf.append(model_rf_tmp.predict(X_test))\n",
    "for j in range(10,110,10):\n",
    "    model_rf_tmp = RandomForestClassifier(n_estimators=j) \n",
    "    model_rf.append(model_rf_tmp.fit(X_train, y_train))\n",
    "    y_pred_rf.append(model_rf_tmp.predict(X_test))\n",
    "    \n",
    "model_svm_lin=SVC(kernel='linear',C=32,gamma=0.01,probability=True)\n",
    "model_svm_lin.fit(X_train,y_train)\n",
    "y_pred_svm_lin=model_svm_lin.predict(X_test)\n",
    "\n",
    "model_svm_pol=SVC(kernel='poly',C=32,gamma=0.01,probability=True)\n",
    "model_svm_pol.fit(X_train,y_train)\n",
    "y_pred_svm_pol=model_svm_pol.predict(X_test)\n",
    "\n",
    "model_svm_rbf=SVC(kernel='rbf',C=32,gamma=0.01,probability=True)\n",
    "model_svm_rbf.fit(X_train,y_train)\n",
    "y_pred_svm_rbf=model_svm_rbf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "283a67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm_rbf=SVC(kernel='rbf',probability=True)\n",
    "model_svm_rbf.fit(X_train,y_train)\n",
    "y_pred_svm_rbf=model_svm_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8af27",
   "metadata": {},
   "source": [
    "### Confusion matrices\n",
    "\n",
    "Now that we have made our predictions with the different classifiers, we are interested in checking the generalization performance of our models. This will be done using the [__confusion matrix__](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay). To do this, use the metrics module in the scikit library to create confusion matrices for our train and test data. Build confusion matrices for the three types of classifiers used above. You can also observe what happens when you consider different numbers of neighbors (for the k-nearest neighbors) and different tree depths (for the decision tree). What can you conclude from these different results?\n",
    "\n",
    "<span style='color:red'> Add the confusion matrices for the random forests with different numbers of estimators too. How do they behave in comparison to the other classifiers? </span>\n",
    "\n",
    "<span style='color:red'> Add the confusion matrices for the SVM. How do they behave in comparison to the other classifiers? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the confusion matrices in one figure as three subplots in two rows, one for training and one for testing data\n",
    "k=5\n",
    "depth=10\n",
    "n_est=100\n",
    "norm_meth=None\n",
    "\n",
    "# display the confusion matrices in one figure as three subplots in two rows, one for training and one for testing data\n",
    "fig,ax=plt.subplots(2,5, figsize=(16,8))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "cm_display_log_reg = ConfusionMatrixDisplay.from_estimator(model_log_reg,X_train,y_train, normalize=norm_meth, colorbar=False,ax=ax[0][0])\n",
    "ax[0][0].set_title('Logistic regression')\n",
    "cm_display_knn = ConfusionMatrixDisplay.from_estimator(model_knn[k-1],X_train,y_train, normalize=norm_meth, colorbar=False,ax=ax[0][1])\n",
    "ax[0][1].set_title('k-nearest neighbours')\n",
    "cm_display_tree = ConfusionMatrixDisplay.from_estimator(model_tree[depth-1],X_train,y_train, normalize=norm_meth, colorbar=False,ax=ax[0][2])\n",
    "ax[0][2].set_title('Decision tree')\n",
    "cm_display_rf = ConfusionMatrixDisplay.from_estimator(model_rf[int(n_est/10)],X_train,y_train, normalize=norm_meth, colorbar=False,ax=ax[0][3])\n",
    "ax[0][3].set_title('Random forest')\n",
    "cm_display_svm = ConfusionMatrixDisplay.from_estimator(model_svm_rbf,X_train,y_train, normalize=norm_meth, colorbar=False,ax=ax[0][4])\n",
    "ax[0][4].set_title('Support vector machine')\n",
    "\n",
    "cm_display_log_reg = ConfusionMatrixDisplay.from_estimator(model_log_reg,X_test,y_test, normalize=norm_meth, colorbar=False,ax=ax[1][0])\n",
    "cm_display_knn = ConfusionMatrixDisplay.from_estimator(model_knn[k-1],X_test,y_test, normalize=norm_meth, colorbar=False,ax=ax[1][1])\n",
    "cm_display_tree = ConfusionMatrixDisplay.from_estimator(model_tree[depth-1],X_test,y_test, normalize=norm_meth, colorbar=False,ax=ax[1][2])\n",
    "cm_display_rf = ConfusionMatrixDisplay.from_estimator(model_rf[int(n_est/10)],X_test,y_test, normalize=norm_meth, colorbar=False,ax=ax[1][3])\n",
    "cm_display_svm = ConfusionMatrixDisplay.from_estimator(model_svm_rbf,X_test,y_test, normalize=norm_meth, colorbar=False,ax=ax[1][4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dd7655",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "Based on the results obtained from the confusion matrices, we will build a panda datraframe to visualize the metrics obtained for our test data predictions. Its table should contain the following columns: 'Classifier', 'True negatives', 'False positives', 'False negatives', 'True positives', 'Positive predictive value', 'Negative predictive value', 'True positive rate', 'True negative rate', 'Log loss error', 'Accuracy', 'Area under the curve'. Do this for all four types of classifiers used. Read the documentation found in the [__sklearn.metrics.confusion_matrix__](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) module if needed and search for the other metrics accordingly.\n",
    "\n",
    "To start, you will need to initialize a dataframe with the column names and then use the __.loc__ function to add rows.\n",
    "\n",
    "How do the numerical values compare to the confusion matrices you had displayed?\n",
    "\n",
    "<span style='color:red'> Add the values for the SVM. How do they behave in comparison to the other classifiers? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set k and max_depth and n_estimators\n",
    "k=20\n",
    "depth=10\n",
    "n_est=10\n",
    "\n",
    "# initialize the pandas dataframe with the correct column names\n",
    "df_metrics=pd.DataFrame(columns=['Classifier','True negatives', 'False positives', 'False negatives','True positives','Positive predictive value','Negative predictive value','True positive rate','True negative rate', 'Log loss error','Accuracy','Area under the curve'])\n",
    "\n",
    "# compute the metrics for each classifier and add the corresponding rows to the dataframe\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_log_reg).ravel()\n",
    "df_metrics.loc[0]=['Logistic regression',tn,fp,fn,tp,tp/(tp+fp),tn/(fn+tn),tp/(tp+fn),tn/(fp+tn),log_loss(y_test, model_log_reg.predict_proba(X_test)),accuracy_score(y_test, y_pred_log_reg),roc_auc_score(y_test, model_log_reg.predict_proba(X_test)[:,1])]\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn[k-1]).ravel()\n",
    "df_metrics.loc[1]=['k-nearest neighbour',tn,fp,fn,tp,tp/(tp+fp),tn/(fn+tn),tp/(tp+fn),tn/(fp+tn),log_loss(y_test, model_knn[k-1].predict_proba(X_test)),accuracy_score(y_test, y_pred_knn[k-1]),roc_auc_score(y_test, model_knn[k-1].predict_proba(X_test)[:,1])]\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_tree[depth-1]).ravel()\n",
    "df_metrics.loc[2]=['Decision tree',tn,fp,fn,tp,tp/(tp+fp),tn/(fn+tn),tp/(tp+fn),tn/(fp+tn),log_loss(y_test, model_tree[depth-1].predict_proba(X_test)),accuracy_score(y_test, y_pred_tree[depth-1]),roc_auc_score(y_test, model_tree[depth-1].predict_proba(X_test)[:,1])]\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf[int(n_est/10)]).ravel()\n",
    "df_metrics.loc[3]=['Random Forest',tn,fp,fn,tp,tp/(tp+fp),tn/(fn+tn),tp/(tp+fn),tn/(fp+tn),log_loss(y_test, model_rf[int(n_est/10)].predict_proba(X_test)),accuracy_score(y_test, y_pred_rf[int(n_est/10)]),roc_auc_score(y_test, model_rf[int(n_est/10)].predict_proba(X_test)[:,1])]\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm_rbf).ravel()\n",
    "df_metrics.loc[4]=['SVM',tn,fp,fn,tp,tp/(tp+fp),tn/(fn+tn),tp/(tp+fn),tn/(fp+tn),log_loss(y_test, model_svm_rbf.predict_proba(X_test)),accuracy_score(y_test, y_pred_svm_rbf),roc_auc_score(y_test, model_svm_rbf.predict_proba(X_test)[:,1])]\n",
    "\n",
    "\n",
    "# display the data frame\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f750c8c7",
   "metadata": {},
   "source": [
    "#### ROC curves\n",
    "\n",
    "Now we will use the ROC curves to analyze the performance of our classifiers for prediction. For this task you will need to calculate the probability estimate for all the binary classes of the model. See documentation for the methods predict_proba(...), roc_curve(...) and RocCurveDisplay(...).\n",
    "\n",
    "1. First use the k-nearest neighbors classifier and plot the ROC curve for models where k = 1, 5, 9, 13, 17. How does the number of nearest neighbors influence the ROC curve? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "for i in range(0,20,4):\n",
    "    y_score_knn=model_knn[i].predict_proba(X_test)[:,1]\n",
    "    fpr_knn, tpr_knn, _ = roc_curve(y_test, y_score_knn)\n",
    "    roc_display_knn = RocCurveDisplay(fpr=fpr_knn, tpr=tpr_knn).plot(ax,label='%s nearest neighbours' %(i+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729bffa2",
   "metadata": {},
   "source": [
    "2. Do the same thing for the decision tree classifier. How does the max_depth influences the ROC curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6aac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "for i in range(0,20,4):\n",
    "    y_score_tree=model_tree[i].predict_proba(X_test)[:,1]\n",
    "    fpr_tree, tpr_tree, _ = roc_curve(y_test, y_score_tree)\n",
    "    roc_display_tree = RocCurveDisplay(fpr=fpr_tree, tpr=tpr_tree).plot(ax,label='Decision tree depth %s' %(i+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451aae2f",
   "metadata": {},
   "source": [
    "3. Similarly, display the ROC curve for the random forest classifier for different n_estimators. How does this variable influence the ROC curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01835c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "for i in range(10,50,10):\n",
    "    y_score_rf=model_rf[int(i/10)].predict_proba(X_test)[:,1]\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(y_test, y_score_rf)\n",
    "    roc_display_rf = RocCurveDisplay(fpr=fpr_rf, tpr=tpr_rf).plot(ax,label='Random forest n=%s' %(int(i)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558082a3",
   "metadata": {},
   "source": [
    "4. Finally, plot the ROC curves for the logistic regression classifier, k-nearest neighbors classifier (for k = 5), the decision tree classifier (for max_depth = 11) and for the random forest classifier (n_estimators=100).  Of course, you can play with the model parameters or divide between testing and training performance. Which differences do you notice between the different  models?\n",
    "\n",
    "<span style='color:red'> 09.06.2023: Add the ROC curve for the best performing SVM. How does it compare? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17488cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_log_reg=model_log_reg.predict_proba(X_test)[:,1]\n",
    "fpr_log_reg, tpr_log_reg, _ = roc_curve(y_test, y_score_log_reg)\n",
    "y_score_knn=model_knn[10].predict_proba(X_test)[:,1]\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_score_knn)\n",
    "y_score_tree=model_tree[10].predict_proba(X_test)[:,1]\n",
    "fpr_tree, tpr_tree, _ = roc_curve(y_test, y_score_tree)\n",
    "y_score_rf=model_rf[10].predict_proba(X_test)[:,1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_score_rf)\n",
    "y_score_svm=model_svm_rbf.predict_proba(X_test)[:,1]\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, y_score_svm)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "roc_displayog_reg = RocCurveDisplay(fpr=fpr_log_reg, tpr=tpr_log_reg).plot(ax,label='Logistic regression')\n",
    "roc_display_knn = RocCurveDisplay(fpr=fpr_knn, tpr=tpr_knn).plot(ax,label='k-nearest neighbours')\n",
    "roc_display_tree = RocCurveDisplay(fpr=fpr_tree, tpr=tpr_tree).plot(ax,label='Decision tree')\n",
    "roc_display_rf = RocCurveDisplay(fpr=fpr_rf, tpr=tpr_rf).plot(ax,label='Random forest')\n",
    "roc_display_svm = RocCurveDisplay(fpr=fpr_svm, tpr=tpr_svm).plot(ax,label='Support vector machine')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f65cd1",
   "metadata": {},
   "source": [
    "Overall, how do the ROC curves compare to the metrics you had displayed in the dataframe above?\n",
    "\n",
    "Using the following cell, you can display the decision tree that you have trained. Run the code for different __max_depth__ and see how your tree changes. What do you conclude from the tree structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf=model_tree[2]\n",
    "y_names=['no metal','metal']\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(clf,  \n",
    "                   feature_names=df.drop([\"formula\",\"is_metal\",\"composition\"],axis=1).columns, \n",
    "                   class_names=y_names,\n",
    "                   filled=True)\n",
    "#fig.savefig(\"decision_tree_depth%d.png\" % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d39a987",
   "metadata": {},
   "source": [
    "With trees and random forests we can determine the [__feature_importances__](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html) in a straightforward manner. The following cell lets you compute the feature importances based on the mean decrease in Gini impurity for the random forests you have trained and plot them in descending order. How does this agree with the tree you plotted in the previous cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48481a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=df.drop([\"formula\",\"is_metal\",\"composition\"],axis=1).columns\n",
    "importances = model_rf[2].feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model_rf[2].estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "sorted_idx = (-importances).argsort()[:20]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "forest_importances[sorted_idx].plot.bar(yerr=std[sorted_idx], ax=ax)\n",
    "ax.set_title(\"Feature importances\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05074069",
   "metadata": {},
   "source": [
    "To compute the proximity matrix based on your random forests, use the following cell. The code was taken from [this stackoverflow entry](https://stackoverflow.com/questions/18703136/proximity-matrix-in-sklearn-ensemble-randomforestclassifier). You can vary which random forest model you use and have a look at the resulting visualization of proximities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d1a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is taken from https://stackoverflow.com/questions/18703136/proximity-matrix-in-sklearn-ensemble-randomforestclassifier\n",
    "# which is available under a CC BY-SA 3.0 license, see here for more information: https://creativecommons.org/licenses/by-sa/3.0/ \n",
    "\n",
    "def proximityMatrix(model, X, normalize=True):      \n",
    "\n",
    "    terminals = model.apply(X)\n",
    "    nTrees = terminals.shape[1]\n",
    "\n",
    "    a = terminals[:,0]\n",
    "    proxMat = 1*np.equal.outer(a, a)\n",
    "\n",
    "    for i in range(1, nTrees):\n",
    "        a = terminals[:,i]\n",
    "        proxMat += 1*np.equal.outer(a, a)\n",
    "\n",
    "    if normalize:\n",
    "        proxMat = proxMat / nTrees\n",
    "\n",
    "    return proxMat   \n",
    "\n",
    "\n",
    "pM=proximityMatrix(model_rf[2], X, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66832528",
   "metadata": {},
   "source": [
    "The proximity matrix $PM$ can be converted into a dissimilarity matrix $DM=1-PM$ and using multidimensional scaling, it can then be projected onto a 2D-plane, as described in [Gilles Louppe - Understanding Random Forests: From Theory to Practice](https://arxiv.org/abs/1407.7502).\n",
    "To do so, we used the sklearn method [MDS](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html)\n",
    "and adapted the transformation and plotting routine described [here](https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py). Execute the following two cells to visualize the proximities for our classes metals and non-metals. \n",
    "\n",
    "What does the result suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6757e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "transformer=manifold.MDS(n_components=2, dissimilarity='precomputed', n_init=1, normalized_stress=\"auto\")\n",
    "transformer.dissimilarity_matrix_=(1-pM)\n",
    "\n",
    "projections = transformer.fit_transform((1-pM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ea619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def plot_embedding(XX, title):\n",
    "    _, ax = plt.subplots(figsize=(6,6))\n",
    "    XX = MinMaxScaler().fit_transform(XX)\n",
    "\n",
    "    for ff in [True,False]:\n",
    "        ax.scatter(\n",
    "            *XX[y == ff].T,\n",
    "            label=ff,\n",
    "            s=60,\n",
    "            alpha=0.425,\n",
    "            zorder=2,\n",
    "        )\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plot_embedding(projections,'Random forest proximities metallicity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc04a9e",
   "metadata": {},
   "source": [
    "For comparison, you can run the cell below which will compute the proximity matrix and display the results for the digits data set shown in the lecture. This cell is adapted from [the scikit documentation](https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py), which is available under the BSD license (© 2007 - 2023, scikit-learn developers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1871b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "def plot_embeddingd(Xd, title):\n",
    "    _, ax = plt.subplots(figsize=(6,6))\n",
    "    Xd = MinMaxScaler().fit_transform(Xd)\n",
    "\n",
    "    for digit in digits.target_names:\n",
    "        ax.scatter(\n",
    "            *Xd[yd == digit].T,\n",
    "            label=f\"${digit}$\",\n",
    "            s=30,\n",
    "            color=plt.cm.Set3(digit),\n",
    "            zorder=2,\n",
    "        )\n",
    "    ax.legend(loc='lower right', bbox_to_anchor=(1.15, 0.025))\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "digits = load_digits()\n",
    "Xd, yd = digits.data, digits.target\n",
    "n_samples, n_features = Xd.shape\n",
    "rf_model=RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(Xd, yd)\n",
    "\n",
    "pMd=proximityMatrix(rf_model, Xd, normalize=True)\n",
    "\n",
    "transformerd=manifold.MDS(n_components=2, dissimilarity='precomputed', n_init=1, normalized_stress=\"auto\")\n",
    "transformerd.dissimilarity_matrix_=(1-pMd)\n",
    "\n",
    "projectionsd = transformerd.fit_transform((1-pMd))\n",
    "\n",
    "plot_embeddingd(projectionsd,'Random forest proximities digit data set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff68bbe7",
   "metadata": {},
   "source": [
    "To determine the feature importance for any classifier, you can use __permutation importance__, similarly as for the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm_importance = permutation_importance(model_svm_rbf, X_test, y_test)\n",
    "imp_mean=pd.Series(np.absolute(perm_importance.importances_mean), index=feature_names)\n",
    "imp_std=pd.Series(perm_importance.importances_std, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "sorted_idx = imp_mean.argsort()[::-1][:20]\n",
    "imp_mean[sorted_idx].plot.bar(yerr=imp_std[sorted_idx], ax=ax)\n",
    "ax.set_ylabel(\"Feature importance\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74657f7f",
   "metadata": {},
   "source": [
    "<a name=\"cite_note-1\"></a>1.[^](#cite_ref-1) Y. Zhuo, A.M. Tehrani, and J. Brgoch, J. Phys. Chem. Lett. 2018, 9, 7, 1668–1673, https://doi.org/10.1021/acs.jpclett.8b00124"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947dd39",
   "metadata": {},
   "source": [
    "### Multilayer perceptron\n",
    "\n",
    "In this part of the notebook you will implement a multilayer perceptron using the [__MLPClassifier__](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#) to classify the metallicity dataset.\n",
    "\n",
    "Begin by implementing the MLPClassifier using one hidden layer and looping over the number of nodes in that hidden layer, using numbers in the range of $\\left[1, 103\\right]$ - use an appropriate step size. Allow a maximum of 500 iterations. Set __random_state__ to 42 to ensure that your classifiers are generally comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b31a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network (loop over number of nodes in hidden layers)\n",
    "model_nn=[] # define the model array\n",
    "y_pred_nn=[]# define the prediction array\n",
    "stp_size= # add the step size required here\n",
    "for k in range('#start_param,#end_param,#increment'): \n",
    "    model_nn_tmp = MLPClassifier('#hidden_layers, #max_iter, #random_state')\n",
    "    #appendfit model\n",
    "    #append prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744c1077",
   "metadata": {},
   "source": [
    "For the MLP classifiers that you trained, display the training loss at each iteration. How does the number of nodes in the hidden layer influence the training loss? Why do certain models not train until the maximum number of iterations that you had defined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43535c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots('#fig_size')\n",
    "for k in range(1,np.size(model_nn)+'n'):\n",
    "    plt.plot(np.arange(0,model_nn[k-1].n_iter_),model_nn[k-1].loss_curve_,\n",
    "             label='# nodes in hidden layer =%s' %(int((k-1)*stp_size+1)))\n",
    "#plot ylabel\n",
    "#plot xlabel\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.9, 1.02))\n",
    "#display graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87fdbe",
   "metadata": {},
   "source": [
    "Similarly, plot the (test) accuracy of each MLP classifier against the number of nodes in the layer. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0706b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "for k in range('#start,#end'):\n",
    "    plt.scatter(int((k-1)*stp_size+1),accuracy_score(y_test,y_pred_nn[k-1]),color='k')\n",
    "#plot ylabel\n",
    "#plot xlabel\n",
    "#print graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f18def",
   "metadata": {},
   "source": [
    "Now that we have seen how the MLP classifier behaves if we have only one hidden layer with different numbers of nodes, we want to see how different numbers of hidden layers with a fixed number of nodes each behave. Define MLP classifiers looping over the number of hidden layers, selecting the number of nodes that previously achieved the highest accuracy. Use up to 20 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c1a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network (loop over number of hidden layers)\n",
    "model_nn=[]\n",
    "y_pred_nn=[]\n",
    "for k in range('#start,#end'):\n",
    "    hl=np.ones((k))*10\n",
    "    model_nn_tmp = MLPClassifier(hidden_layer_sizes=(hl.astype(int)), '#max_iter', '#random_state')\n",
    "    #append fit model\n",
    "    #append prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d1086",
   "metadata": {},
   "source": [
    "Again, plot the (training) loss curve for the different numbers of hidden layers. What do you observe in this case? Why do certain models not train until the maximum number of iterations that you had defined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c6244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "for k in range('#start_param,#end_param,#increment'):\n",
    "    plt.plot(np.arange(0,model_nn[k-1].n_iter_),model_nn[k-1].loss_curve_,\n",
    "             label='# hidden layers =%s' %(int(k)))\n",
    "#plot ylabel\n",
    "#plot xlabel\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.9, 1.02))\n",
    "#print graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca03e0",
   "metadata": {},
   "source": [
    "Plot the accuracy against the number of hidden layers. What trend are you observing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ffd8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "for k in range('#start,#end'):\n",
    "    plt.scatter(k,accuracy_score(y_test,y_pred_nn[k-1]),color='k')\n",
    "#plot ylabel\n",
    "#plot xlabel\n",
    "#print graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf5ae09",
   "metadata": {},
   "source": [
    "Clearly, finding the optimal number of hidden layers and nodes per hidden layer it a difficult optimization problem that generally requires careful consideration. You can find extensive literature on the subject. To generally find the answer to this question for a specific problem, you need to perform a cross-validation and assess the test loss for varying numbers of hidden layers and nodes. However, there are some general rules that you can make use of, look for example [here](https://www.heatonresearch.com/2017/06/01/hidden-layers.html) or [here](https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e). \n",
    "\n",
    "Therefore, using __KFold__ let's perform a 5-fold cross-valiadation computing the mean accuracy for different MLP classifiers with numbers of hidden layers being 1 or 2 and number of nodes per hidden layer being up to 10. For simplicity, we only allow the same number of nodes in the first and second hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Add the missing params bellow\n",
    "kf = KFold('#n_splits,#random_state,#shuffle')\n",
    "mean_acc=[]\n",
    "\n",
    "for i in ['i,i++']:\n",
    "    for j in range('j,j++'):\n",
    "        hl=np.ones((i))*j\n",
    "        clf='add classifier'\n",
    "        mean_acc.append(np.mean(cross_val_score(clf, X, y, scoring='accuracy', cv=kf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935bd940",
   "metadata": {},
   "source": [
    "Plot the mean accuracy as a function of the number of hidden layers and number of nodes per layer. which classifier performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "color=['k','r']\n",
    "for i in [1,2]:\n",
    "    plt.scatter(np.arange(1,11),mean_acc[(i-1)*10:i*10],color=color[i-1],label='# hidden layers =%s' %(int(i)))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of nodes in hidden layer')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.9, 1.02))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f10a16",
   "metadata": {},
   "source": [
    "You will produce results of different quality if you set cv to an integer number. In this case, sklearn uses the [__stratified Kfold__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#) to produce the folds for cross-validation. This means, that the percentage of each class (metal, non-metal) will be preserved in each fold. This should generally lead to a higher cross-validation score, in particular if we have a very uneven distribution of the classes. \n",
    "In addition to simply using (stratified) kfold, we can also shuffle the data, so that the folds are not taken sequentially but from a shuffled dataset. To see how the folds and the percentage of the class changes the next cell trials four different kfold settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7dc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf1 = KFold(n_splits=5)\n",
    "kf2 = KFold(n_splits=5,random_state=1,shuffle=True)\n",
    "skf1= StratifiedKFold(n_splits=5)\n",
    "skf2= StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "#Add the code blocks missing bellow\n",
    "fig,ax=plt.subplots(4,5, figsize=(16,8))\n",
    "perc_y=[]\n",
    "for i, (train_index, test_index) in enumerate(kf1.split(X, y)):\n",
    "    ax[0][i].scatter(train_index,\n",
    "                df['is_metal'].iloc[train_index],color='k')\n",
    "    ax[0][i].scatter(test_index,\n",
    "                df['is_metal'].iloc[test_index],color='r')\n",
    "    perc_y.append(np.size(np.where(df['is_metal'].iloc[test_index]==1))/(np.size(np.where(df['is_metal']==1))))\n",
    "print('Percentage is metal in test', np.round(perc_y,2))\n",
    "perc_y=[]\n",
    "for i, (train_index, test_index) in enumerate(kf2.split(X, y)):\n",
    "    # add code here\n",
    "perc_y=[]\n",
    "for i, (train_index, test_index) in enumerate(skf1.split(X, y)):\n",
    "    # add code here\n",
    "print('Percentage is metal in test', np.round(perc_y,2))\n",
    "perc_y=[]\n",
    "for i, (train_index, test_index) in enumerate(skf2.split(X, y)):\n",
    "   # add code here\n",
    "print('Percentage is metal in test', np.round(perc_y,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6766fa",
   "metadata": {},
   "source": [
    "As you can see, the stratified kfold produces more evenly distributed folds, which should result in a higher cross-validation score. In the next cell, we use all methods to produce the folds to assess their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a308576",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc=[]\n",
    "#Add the missing params indicated below\n",
    "for i in [1,2]:\n",
    "    for j in range(1,3):\n",
    "        hl=np.ones((i))*j\n",
    "        clf=MLPClassifier(hidden_layer_sizes=(hl.astype(int)), max_iter=500, random_state=42)\n",
    "        cvs=cross_val_score(clf, X, y, scoring='accuracy', cv='#add value here')\n",
    "        mean_acc.append(np.round(np.mean(cvs),2))\n",
    "        print('Kfold validation, non-shuffled, accuracy', np.round(cvs,2))\n",
    "print('Kfold validation, non-shuffled, mean accuracy', mean_acc)\n",
    "\n",
    "mean_acc=[]\n",
    "#Add the missing params indicated below\n",
    "for i in [1,2]:\n",
    "    for j in range(1,3):\n",
    "        hl=np.ones((i))*j\n",
    "        clf=MLPClassifier(hidden_layer_sizes=(hl.astype(int)), max_iter=500, random_state=42)\n",
    "        cvs=cross_val_score(clf, X, y, scoring='accuracy', cv='#add value here')\n",
    "        mean_acc.append(np.round(np.mean(cvs),2))\n",
    "        print('Kfold validation, shuffled, accuracy', np.round(cvs,2))\n",
    "print('Kfold validation, shuffled, mean accuracy', mean_acc)\n",
    "\n",
    "mean_acc=[]\n",
    "#Add the missing params indicated below\n",
    "for i in [1,2]:\n",
    "    for j in range(1,3):\n",
    "        hl=np.ones((i))*j\n",
    "        clf=MLPClassifier(hidden_layer_sizes=(hl.astype(int)), max_iter=500, random_state=42)\n",
    "        cvs=cross_val_score(clf, X, y, scoring='accuracy', cv='#add value here')\n",
    "        mean_acc.append(np.round(np.mean(cvs),2))\n",
    "        print('Stratified Kfold validation, non-shuffled, accuracy', np.round(cvs,2))\n",
    "print('Stratified Kfold validation, non-shuffled, mean accuracy', mean_acc)\n",
    "\n",
    "mean_acc=[]\n",
    "#Add the missing params indicated bellow\n",
    "for i in [1,2]:\n",
    "    for j in range(1,3):\n",
    "        hl=np.ones((i))*j\n",
    "        clf=MLPClassifier(hidden_layer_sizes=(hl.astype(int)), max_iter=500, random_state=42)\n",
    "        cvs=cross_val_score(clf, X, y, scoring='accuracy', cv='#add value here')\n",
    "        mean_acc.append(np.round(np.mean(cvs),2))\n",
    "        print('Stratified Kfold validation, shuffled, accuracy',np.round(cvs,2))\n",
    "print('Stratified Kfold validation, shuffled, mean accuracy', mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e2d95",
   "metadata": {},
   "source": [
    "Clearly, the stratified kfold without shuffling performs worst, which is surprising. If we were to look further into the datasets it created, we might find the reason for this particular behaviour. The kfold itself performs well enough against the stratified kfold with shuffling, because the classes are well distributed within the dataset and the class fraction is almost 1:1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
